{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided to preprocess the input dataset (to later reuse it and also to recompute pharmacophores on it), to make this reproducible I'm using this notebook.\n",
    "\n",
    "I also want to take a look at the train/test split and construct a better validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODEPATH = \"../code\"\n",
    "if not CODEPATH in sys.path:\n",
    "    sys.path.append(CODEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.cleaner import split_df, clean_smiles, collect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = Path(\"../data\")\n",
    "train_df = pd.read_csv(DATAPATH / \"train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(DATAPATH / \"test.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot parse ['[I-]', '[K+]'] ['K']\n"
     ]
    }
   ],
   "source": [
    "train_df[\"cleaned\"] = train_df.Smiles.apply(clean_smiles)\n",
    "test_df[\"cleaned\"] = test_df.Smiles.apply(clean_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Active</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1ccc2[nH]cc(CCN)c2c1</td>\n",
       "      <td>False</td>\n",
       "      <td>COc1ccc2[nH]cc(CCN)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCCN1CCC[C@H](c2cccc(O)c2)C1.Cl</td>\n",
       "      <td>False</td>\n",
       "      <td>CCCN1CCC[C@H](c2cccc(O)c2)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...</td>\n",
       "      <td>False</td>\n",
       "      <td>O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...</td>\n",
       "      <td>False</td>\n",
       "      <td>Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1</td>\n",
       "      <td>False</td>\n",
       "      <td>Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Smiles  Active  \\\n",
       "0                            COc1ccc2[nH]cc(CCN)c2c1   False   \n",
       "1                    CCCN1CCC[C@H](c2cccc(O)c2)C1.Cl   False   \n",
       "2  O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...   False   \n",
       "3  Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...   False   \n",
       "4            Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1   False   \n",
       "\n",
       "                                             cleaned  \n",
       "0                            COc1ccc2[nH]cc(CCN)c2c1  \n",
       "1                       CCCN1CCC[C@H](c2cccc(O)c2)C1  \n",
       "2  O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...  \n",
       "3  Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...  \n",
       "4            Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_splitted = split_df(\n",
    "    train_df,\n",
    "    smiles_col=\"cleaned\",\n",
    "    keep_columns=[\"Smiles\", \"cleaned\"],\n",
    ")\n",
    "test_df_splitted = split_df(test_df, smiles_col=\"cleaned\", keep_columns=[\"Smiles\", \"cleaned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>Active</th>\n",
       "      <th>num_parts</th>\n",
       "      <th>original_Smiles</th>\n",
       "      <th>original_cleaned</th>\n",
       "      <th>part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COc1ccc2[nH]cc(CCN)c2c1</td>\n",
       "      <td>COc1ccc2[nH]cc(CCN)c2c1</td>\n",
       "      <td>COc1ccc2[nH]cc(CCN)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CCCN1CCC[C@H](c2cccc(O)c2)C1.Cl</td>\n",
       "      <td>CCCN1CCC[C@H](c2cccc(O)c2)C1</td>\n",
       "      <td>CCCN1CCC[C@H](c2cccc(O)c2)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...</td>\n",
       "      <td>O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...</td>\n",
       "      <td>O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...</td>\n",
       "      <td>Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...</td>\n",
       "      <td>Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1</td>\n",
       "      <td>Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1</td>\n",
       "      <td>Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index  Active  num_parts  \\\n",
       "0               0   False        1.0   \n",
       "1               1   False        1.0   \n",
       "2               2   False        1.0   \n",
       "3               3   False        1.0   \n",
       "4               4   False        1.0   \n",
       "\n",
       "                                     original_Smiles  \\\n",
       "0                            COc1ccc2[nH]cc(CCN)c2c1   \n",
       "1                    CCCN1CCC[C@H](c2cccc(O)c2)C1.Cl   \n",
       "2  O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...   \n",
       "3  Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...   \n",
       "4            Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1   \n",
       "\n",
       "                                    original_cleaned  \\\n",
       "0                            COc1ccc2[nH]cc(CCN)c2c1   \n",
       "1                       CCCN1CCC[C@H](c2cccc(O)c2)C1   \n",
       "2  O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...   \n",
       "3  Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...   \n",
       "4            Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1   \n",
       "\n",
       "                                                part  \n",
       "0                            COc1ccc2[nH]cc(CCN)c2c1  \n",
       "1                       CCCN1CCC[C@H](c2cccc(O)c2)C1  \n",
       "2  O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...  \n",
       "3  Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...  \n",
       "4            Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_splitted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Active\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a test to see that it is revertible\n",
    "df = collect_df(train_df_splitted).rename(columns={\"original_Smiles\": \"Smiles\"})\n",
    "df.merge(train_df, on=[\"Smiles\", \"Active\"], how=\"left\").shape == train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_splitted.to_csv(DATAPATH/\"train_splitted.csv\")\n",
    "test_df_splitted.to_csv(DATAPATH/\"test_splitted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n"
     ]
    }
   ],
   "source": [
    "from DeepPurpose.utils import smiles2pubchem, smiles2morgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5758/5758 [04:49<00:00, 19.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "train_fingerprints = []\n",
    "for original_index, part, active in tqdm(train_df_splitted[[\"original_index\", \"part\", \"Active\"]].values):\n",
    "    fp = smiles2pubchem(part)\n",
    "    train_fingerprints.append((original_index, part, active, fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1681/1681 [01:47<00:00, 15.71it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fingerprints = []\n",
    "for original_index, part in tqdm(test_df_splitted[[\"original_index\", \"part\"]].values):\n",
    "    fp = smiles2pubchem(part)\n",
    "    test_fingerprints.append((original_index, part, fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_fp = np.stack([x[-1]for x in train_fingerprints])\n",
    "test_fp = np.stack([x[-1] for x in test_fingerprints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "x_train = np.concatenate([train_fp, test_fp], axis=0)\n",
    "y_train = np.concatenate([np.zeros(train_fp.shape[:1]), np.ones(test_fp.shape[:1])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618ab45a987549aeb15c0eb962247d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f90e37f5290>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    random_seed=42, depth=11,\n",
    "    iterations=100,\n",
    "    auto_class_weights=\"Balanced\", eval_metric=\"F1\"\n",
    ")\n",
    "model.fit(x_train, y_train, eval_set=(x_train, y_train),\n",
    "    plot=True,silent=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6812, 7439, 5758)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argmax(predictions, 1) == y_train).sum(), len(y_train), len(train_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = predictions[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72892155, 0.82534539, 0.75346306, ..., 0.54401058, 0.76688576,\n",
       "       0.65985463])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1[y_train==1]  # test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = preds1[y_train==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.80396857, 0.79183887, 0.78817349, ..., 0.34115085, 0.34108438,\n",
       "        0.34108438]),\n",
       " 1681)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.argsort(train_preds)[::-1]\n",
    "train_preds[ids][:len(test_fp)], len(test_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = np.asarray([x[2] for x in train_fingerprints])\n",
    "active1 = np.where(activities)[0]\n",
    "active0 = np.where(~activities)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108 43\n"
     ]
    }
   ],
   "source": [
    "N = 0.20\n",
    "n1 = int(len(active1)*N)\n",
    "n0 = int(len(active0)*N)\n",
    "print(n0, n1)\n",
    "ids1 = np.argsort(train_preds[active1])[::-1]\n",
    "pos_ids = active1[ids1][:n1]\n",
    "ids0 = np.argsort(train_preds[active0])[::-1]\n",
    "neg_ids = active0[ids0][:n0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03909643788010426, 45)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_ = np.argsort(train_preds)[::-1][:n0+n1]\n",
    "activities[ids_].mean(), activities[ids_].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1151,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ids = np.concatenate([pos_ids, neg_ids])\n",
    "val_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49519580765819243"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(train_preds[val_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2060434529900928"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_ = [x for x in np.arange(len(train_preds)) if x not in val_ids]\n",
    "np.median(train_preds[train_ids_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = np.sort(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_splitted[\"val_index\"] = train_df_splitted.original_index.apply(lambda x: x in set(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_splitted.to_csv(DATAPATH / \"train_splitted_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d632e93423067b2b9b1b8d52846f85c868da433699adad534ad2cc6673775271"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
