{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Custom fingerprints based on rdkit data. \n",
    "Various other things.\n",
    "\n",
    "I need this notebook simply for the code drafts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import RDConfig\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "IPythonConsole.drawOptions.addAtomIndices = False\n",
    "IPythonConsole.drawOptions.addStereoAnnotation = True\n",
    "IPythonConsole.drawOptions.useBWAtomPalette()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from rdkit.Chem import rdMolHash\n",
    "TMP_DIR = Path(\"../tmp\")\n",
    "PHARPATH = Path(\"../tmp/pharmacophores\")\n",
    "DATAPATH = Path(\"../data\")\n",
    "\n",
    "train_df = pd.read_csv(DATAPATH/\"train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(DATAPATH/\"test.csv\", index_col=0)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build library of the molecular fragments and use it\n",
    "https://www.rdkit.org/docs/GettingStartedInPython.html#molecular-fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fName=os.path.join(RDConfig.RDDataDir,'FunctionalGroups.txt')\n",
    "from rdkit.Chem import FragmentCatalog\n",
    "fparams = FragmentCatalog.FragCatParams(1,6,fName)\n",
    "fparams.GetNumFuncGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcat = FragmentCatalog.FragCatalog(fparams)\n",
    "fcgen = FragmentCatalog.FragCatGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5557/5557 [04:12<00:00, 22.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for smiles in tqdm(train_df.Smiles.values):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fcgen.AddFragsFromMol(mol, fcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221893"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcat.GetNumEntries()  # a lot - need to use sparse data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgen = FragmentCatalog.FragFPGenerator()\n",
    "#fp = fpgen.GetFPForMol(ms[8],fcat)\n",
    "#fp.GetNumOnBits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mols = [Chem.MolFromSmiles(smiles) for smiles in train_df.Smiles.values]\n",
    "test_mols = [Chem.MolFromSmiles(smiles) for smiles in test_df.Smiles.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5557/5557 [04:51<00:00, 19.04it/s]\n",
      "100%|██████████| 1614/1614 [01:20<00:00, 20.11it/s]\n"
     ]
    }
   ],
   "source": [
    "fps_train = []\n",
    "for x in tqdm(train_mols):\n",
    "    fps_train.append(fpgen.GetFPForMol(x, fcat))\n",
    "fps_test = []\n",
    "for x in tqdm(test_mols):\n",
    "    fps_test.append(fpgen.GetFPForMol(x, fcat))\n",
    "\n",
    "# fps_test = [fpgen.GetFPForMol(x, fcat) for x in train_mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7f94fe9bea30>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7f94fe9bea80>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7f94fe9be0d0>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7f94fef288a0>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = fpgen.GetFPForMol(train_mols[0],fcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5557/5557 [00:13<00:00, 402.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(fp).shape\n",
    "from scipy.sparse import csr_matrix\n",
    "num_fp = fcat.GetNumEntries()\n",
    "num_entries = len(fps_train)\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "for i, fp in enumerate(tqdm(fps_train)):\n",
    "    bits = list(fp.GetOnBits())\n",
    "    col_indices.extend(bits)\n",
    "    row_indices.extend([i]*len(bits))\n",
    "col_indices = np.asarray(col_indices)\n",
    "row_indices = np.asarray(row_indices)\n",
    "assert len(col_indices) == len(row_indices)\n",
    "values = np.ones((len(col_indices), ))\n",
    "train_frag_matrix = csr_matrix((values, (row_indices, col_indices)), shape=(num_entries, num_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:04<00:00, 390.61it/s]\n"
     ]
    }
   ],
   "source": [
    "row_indices = []\n",
    "col_indices = []\n",
    "for i, fp in enumerate(tqdm(fps_test)):\n",
    "    bits = list(fp.GetOnBits())\n",
    "    col_indices.extend(bits)\n",
    "    row_indices.extend([i]*len(bits))\n",
    "col_indices = np.asarray(col_indices)\n",
    "row_indices = np.asarray(row_indices)\n",
    "assert len(col_indices) == len(row_indices)\n",
    "values = np.ones((len(col_indices), ))\n",
    "test_frag_matrix = csr_matrix((values, (row_indices, col_indices)), shape=(len(fps_test), num_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1614x221893 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 382062 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frag_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True)\n",
    "tfidf_transformer.fit(train_frag_matrix)\n",
    "train_frag_matrix_transformed = tfidf_transformer.transform(train_frag_matrix)\n",
    "test_frag_matrix_transformed = tfidf_transformer.transform(test_frag_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.929846429742504"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED + 4)\n",
    "ids1 = np.where(train_df.Active == 1)[0]\n",
    "ids0 = np.where(train_df.Active == 0)[0]\n",
    "m = len(ids0)\n",
    "rebalanced = np.concatenate([\n",
    "    np.random.choice(ids1, m),\n",
    "    ids0]\n",
    ")\n",
    "subset_ids = np.concatenate([\n",
    "    np.random.choice(ids0, len(ids1)),\n",
    "    ids1\n",
    "])\n",
    "np.median(tfidf_transformer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(y_train):\n",
    "    df, counts = np.unique(y_train, return_counts=True)\n",
    "    m = counts.max()\n",
    "    index = np.arange(len(y_train))\n",
    "    new_index = []\n",
    "    for i, c in zip(df, counts):\n",
    "        ids = y_train == i\n",
    "        values = index[ids]\n",
    "        if c == m:\n",
    "            new_index.extend(values)\n",
    "        else:\n",
    "            new_index.extend(np.random.choice(values, m))\n",
    "    np.random.shuffle(new_index)\n",
    "    return new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf_transformer = TfidfTransformer(smooth_idf=True)\n",
    "#tfidf_transformer.fit(train_frag_matrix_transformed)\n",
    "#frag_matrix_transformed = tfidf_transformer.transform(train_frag_matrix_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n",
      "608\n",
      "650\n",
      "625\n",
      "695\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED + 5)\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "NFOLDS = 5\n",
    "BALANCE_TRAIN = True\n",
    "y_full_train = train_df.Active.values\n",
    "kf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED + 8)\n",
    "kfsplits = kf.split(np.arange(train_df.shape[0]), y_full_train)\n",
    "split_data = dict()\n",
    "all_train_scores = []\n",
    "all_train_scores_rebalanced = []\n",
    "all_test_scores = []\n",
    "for fold, (train_index, test_index) in enumerate(kfsplits):\n",
    "    split_data[fold] = (train_index, test_index)\n",
    "    x_train = train_frag_matrix_transformed[train_index]\n",
    "    y_train = y_full_train[train_index]\n",
    "    x_val = train_frag_matrix_transformed[test_index]\n",
    "    y_val = y_full_train[test_index]\n",
    "    if BALANCE_TRAIN:\n",
    "        balanced_index = balance_data(y_train)\n",
    "        x_train = x_train[balanced_index]\n",
    "        y_train = y_train[balanced_index]\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x_train, y_train)\n",
    "    train_preds = model.predict(train_frag_matrix_transformed)\n",
    "    train_scores = model.predict_proba(train_frag_matrix_transformed)[:, 1]#[rebalanced])[:, 1] \n",
    "    print(train_preds.sum())\n",
    "    all_train_scores.append(train_scores)\n",
    "    train_scores_balanced = model.predict_proba(train_frag_matrix_transformed[rebalanced])[:, 1]#[rebalanced])[:, 1]\n",
    "    all_train_scores_rebalanced.append(train_scores_balanced)\n",
    "\n",
    "    test_scores = model.predict_proba(test_frag_matrix_transformed)[:, 1]#[rebalanced])[:, 1] \n",
    "    all_test_scores.append(test_scores)\n",
    "\n",
    "all_train_scores = np.stack(all_train_scores)\n",
    "all_train_scores_rebalanced = np.stack(all_train_scores_rebalanced)\n",
    "all_test_scores = np.stack(all_test_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(862,)\n",
      "Select threshold on train data without rebalancing 0.6279235594271741\n",
      "304 [0.92767707 0.93234909 0.93122781] 0.6279235594271741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.98      0.95      0.96      5351\n",
      "      Active       0.95      0.98      0.96      5351\n",
      "\n",
      "    accuracy                           0.96     10702\n",
      "   macro avg       0.96      0.96      0.96     10702\n",
      "weighted avg       0.96      0.96      0.96     10702\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       1.00      0.95      0.97      5351\n",
      "      Active       0.41      0.98      0.58       206\n",
      "\n",
      "    accuracy                           0.95      5557\n",
      "   macro avg       0.71      0.96      0.78      5557\n",
      "weighted avg       0.98      0.95      0.96      5557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, f1_score\n",
    "\n",
    "neg = (~train_df.Active).sum()\n",
    "pos = (train_df.Active).sum()\n",
    "train_scores = all_train_scores.mean(0)\n",
    "train_scores_rebalanced = all_train_scores_rebalanced.mean(0)\n",
    "fpr1, tpr1, thresholds1 = roc_curve(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced\n",
    ")\n",
    "print(tpr1.shape)\n",
    "opt_tpr_fpr1 = np.argmax(tpr1-fpr1)\n",
    "optimal_threshold1 = thresholds1[opt_tpr_fpr1]\n",
    "print(\"Select threshold on train data without rebalancing\", optimal_threshold1)\n",
    "print(opt_tpr_fpr1, tpr1[opt_tpr_fpr1-1:opt_tpr_fpr1+2]-fpr1[opt_tpr_fpr1-1:opt_tpr_fpr1+2], optimal_threshold1)\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold1,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold1,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03707036170595645"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Active.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779,)\n",
      "Select threshold on train data without rebalancing 0.7982320159035632\n",
      "181 [0.87207726 0.87693163 0.87674475] 0.7982320159035632\n",
      "on balanced train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.91      0.97      0.94      5351\n",
      "      Active       0.97      0.90      0.93      5351\n",
      "\n",
      "    accuracy                           0.94     10702\n",
      "   macro avg       0.94      0.94      0.94     10702\n",
      "weighted avg       0.94      0.94      0.94     10702\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       1.00      0.97      0.98      5351\n",
      "      Active       0.53      0.90      0.67       206\n",
      "\n",
      "    accuracy                           0.97      5557\n",
      "   macro avg       0.76      0.94      0.83      5557\n",
      "weighted avg       0.98      0.97      0.97      5557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fpr, tpr, thresholds = roc_curve(\n",
    "    train_df.Active.values,\n",
    "    train_scores\n",
    ")\n",
    "print(tpr.shape)\n",
    "tp = tpr*pos\n",
    "fp = fpr*neg\n",
    "fn = (1-tpr)*pos\n",
    "f1 = 2*tp/(2*tp+fp+fn)\n",
    "opt_tpr_fpr = np.argmax(f1)\n",
    "optimal_threshold2 = thresholds[opt_tpr_fpr]\n",
    "print(\"Select threshold on train data without rebalancing\", optimal_threshold2)\n",
    "print(opt_tpr_fpr, tpr[opt_tpr_fpr-1:opt_tpr_fpr+2]-fpr[opt_tpr_fpr-1:opt_tpr_fpr+2], optimal_threshold2)\n",
    "print(\"on balanced train\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select threshold based on mean Active value 0.9629296382940435\n",
      "on balanced train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.91      0.97      0.94      5351\n",
      "      Active       0.97      0.90      0.93      5351\n",
      "\n",
      "    accuracy                           0.94     10702\n",
      "   macro avg       0.94      0.94      0.94     10702\n",
      "weighted avg       0.94      0.94      0.94     10702\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       1.00      0.97      0.98      5351\n",
      "      Active       0.53      0.90      0.67       206\n",
      "\n",
      "    accuracy                           0.97      5557\n",
      "   macro avg       0.76      0.94      0.83      5557\n",
      "weighted avg       0.98      0.97      0.97      5557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimal_threshold3 = 1. - train_df.Active.mean()\n",
    "print(\"Select threshold based on mean Active value\", optimal_threshold3)\n",
    "print(\"on balanced train\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.exp(1)**model.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.ML.InfoTheory import InfoBitRanker\n",
    "# ranker = InfoBitRanker(len(fps[0]), 2)\n",
    "# activities = train_df.Active.values*1\n",
    "# for fp, activity in zip(fps, activities):\n",
    "#     ranker.AccumulateVotes(fp, int(activity))\n",
    "# top5 = ranker.GetTopN(15)\n",
    "# for id,gain,n0,n1 in top5:\n",
    "#     print(int(id),'%.3f'%gain,int(n0),int(n1), fcat.GetEntryDescription(int(id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdkit.ML.InfoTheory.BitClusterer.BitClusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = all_test_scores.mean(0) > optimal_threshold2 # > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Active\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../tmp/multinomial_nb_all_frags_balanced_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d632e93423067b2b9b1b8d52846f85c868da433699adad534ad2cc6673775271"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
