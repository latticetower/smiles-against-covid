{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Custom fingerprints based on rdkit data. \n",
    "Various other things.\n",
    "\n",
    "I need this notebook simply for the code drafts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import RDConfig\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "IPythonConsole.drawOptions.addAtomIndices = False\n",
    "IPythonConsole.drawOptions.addStereoAnnotation = True\n",
    "IPythonConsole.drawOptions.useBWAtomPalette()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from rdkit.Chem import rdMolHash\n",
    "TMP_DIR = Path(\"../tmp\")\n",
    "PHARPATH = Path(\"../tmp/pharmacophores\")\n",
    "DATAPATH = Path(\"../data\")\n",
    "\n",
    "train_df = pd.read_csv(DATAPATH/\"train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(DATAPATH/\"test.csv\", index_col=0)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot parse ['[K+]', '[I-]']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>Active</th>\n",
       "      <th>num_parts</th>\n",
       "      <th>original_Smiles</th>\n",
       "      <th>original_cleaned_smiles</th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COc1ccc2[nH]cc(CCN)c2c1</td>\n",
       "      <td>COc1ccc2[nH]cc(CCN)c2c1</td>\n",
       "      <td>COc1ccc2[nH]cc(CCN)c2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CCCN1CCC[C@H](c2cccc(O)c2)C1.Cl</td>\n",
       "      <td>CCCN1CCC[C@H](c2cccc(O)c2)C1</td>\n",
       "      <td>CCCN1CCC[C@H](c2cccc(O)c2)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...</td>\n",
       "      <td>O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...</td>\n",
       "      <td>O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...</td>\n",
       "      <td>Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...</td>\n",
       "      <td>Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1</td>\n",
       "      <td>Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1</td>\n",
       "      <td>Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index Active  num_parts  \\\n",
       "0               0  False        1.0   \n",
       "1               1  False        1.0   \n",
       "2               2  False        1.0   \n",
       "3               3  False        1.0   \n",
       "4               4  False        1.0   \n",
       "\n",
       "                                     original_Smiles  \\\n",
       "0                            COc1ccc2[nH]cc(CCN)c2c1   \n",
       "1                    CCCN1CCC[C@H](c2cccc(O)c2)C1.Cl   \n",
       "2  O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...   \n",
       "3  Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...   \n",
       "4            Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1   \n",
       "\n",
       "                             original_cleaned_smiles  \\\n",
       "0                            COc1ccc2[nH]cc(CCN)c2c1   \n",
       "1                       CCCN1CCC[C@H](c2cccc(O)c2)C1   \n",
       "2  O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...   \n",
       "3  Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...   \n",
       "4            Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1   \n",
       "\n",
       "                                              Smiles  \n",
       "0                            COc1ccc2[nH]cc(CCN)c2c1  \n",
       "1                       CCCN1CCC[C@H](c2cccc(O)c2)C1  \n",
       "2  O=C(NO)c1cnc(N2CCN(S(=O)(=O)c3ccc4ccccc4c3)CC2...  \n",
       "3  Nc1cccc(CNC(=O)c2ccc(Oc3ccc(OCc4cccc(F)c4)cc3)...  \n",
       "4            Fc1ccccc1CNCc1ccc(-c2ccnc3[nH]ccc23)cc1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEP_DIR = \"../code\"\n",
    "if DEP_DIR not in sys.path:\n",
    "    sys.path.append(DEP_DIR)\n",
    "from common.cleaner import split_df, clean_smiles, collect_df\n",
    "train_df[\"cleaned_smiles\"] = train_df.Smiles.apply(clean_smiles)\n",
    "test_df[\"cleaned_smiles\"] = test_df.Smiles.apply(clean_smiles)\n",
    "train_df = split_df(train_df, smiles_col=\"cleaned_smiles\", keep_columns=[\"cleaned_smiles\", \"Smiles\"])\n",
    "test_df = split_df(test_df, smiles_col=\"cleaned_smiles\", keep_columns=[\"cleaned_smiles\", \"Smiles\"])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_df(test_df, split_col=\"Smiles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5540\n",
       "True      218\n",
       "Name: Active, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Active.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build library of the molecular fragments and use it\n",
    "https://www.rdkit.org/docs/GettingStartedInPython.html#molecular-fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fName=os.path.join(RDConfig.RDDataDir,'FunctionalGroups.txt')\n",
    "from rdkit.Chem import FragmentCatalog\n",
    "fparams = FragmentCatalog.FragCatParams(1,6,fName)\n",
    "fparams.GetNumFuncGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcat = FragmentCatalog.FragCatalog(fparams)\n",
    "fcgen = FragmentCatalog.FragCatGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_df.Smiles.apply(len) == 0).sum()\n",
    "train_df[\"molecule\"] = train_df.Smiles.apply(lambda x: Chem.MolFromSmiles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5758/5758 [04:06<00:00, 23.33it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for mol in tqdm(train_df.molecule.values):\n",
    "    #mol = Chem.MolFromSmiles(smiles)\n",
    "    fcgen.AddFragsFromMol(mol, fcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219855"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcat.GetNumEntries()  # a lot - need to use sparse data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgen = FragmentCatalog.FragFPGenerator()\n",
    "#fp = fpgen.GetFPForMol(ms[8],fcat)\n",
    "#fp.GetNumOnBits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mols = [Chem.MolFromSmiles(smiles) for smiles in train_df.Smiles.values]\n",
    "test_mols = [Chem.MolFromSmiles(smiles) for smiles in test_df.Smiles.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5758/5758 [03:22<00:00, 28.37it/s]\n",
      "100%|██████████| 1681/1681 [01:03<00:00, 26.35it/s]\n"
     ]
    }
   ],
   "source": [
    "fps_train = []\n",
    "for x in tqdm(train_mols):\n",
    "    fps_train.append(fpgen.GetFPForMol(x, fcat))\n",
    "fps_test = []\n",
    "for x in tqdm(test_mols):\n",
    "    fps_test.append(fpgen.GetFPForMol(x, fcat))\n",
    "\n",
    "# fps_test = [fpgen.GetFPForMol(x, fcat) for x in train_mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lacemaker/anaconda3/envs/data_env/share/RDKit/Data'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDConfig.RDDataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7f8c44775170>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7f8c44775300>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7f8c44775350>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7f8c44775440>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = fpgen.GetFPForMol(train_mols[0],fcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5758/5758 [00:14<00:00, 398.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(fp).shape\n",
    "from scipy.sparse import csr_matrix\n",
    "num_fp = fcat.GetNumEntries()\n",
    "num_entries = len(fps_train)\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "for i, fp in enumerate(tqdm(fps_train)):\n",
    "    bits = list(fp.GetOnBits())\n",
    "    col_indices.extend(bits)\n",
    "    row_indices.extend([i]*len(bits))\n",
    "col_indices = np.asarray(col_indices)\n",
    "row_indices = np.asarray(row_indices)\n",
    "assert len(col_indices) == len(row_indices)\n",
    "values = np.ones((len(col_indices), ))\n",
    "train_frag_matrix = csr_matrix((values, (row_indices, col_indices)), shape=(num_entries, num_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1681/1681 [00:04<00:00, 381.56it/s]\n"
     ]
    }
   ],
   "source": [
    "row_indices = []\n",
    "col_indices = []\n",
    "for i, fp in enumerate(tqdm(fps_test)):\n",
    "    bits = list(fp.GetOnBits())\n",
    "    col_indices.extend(bits)\n",
    "    row_indices.extend([i]*len(bits))\n",
    "col_indices = np.asarray(col_indices)\n",
    "row_indices = np.asarray(row_indices)\n",
    "assert len(col_indices) == len(row_indices)\n",
    "values = np.ones((len(col_indices), ))\n",
    "test_frag_matrix = csr_matrix((values, (row_indices, col_indices)), shape=(len(fps_test), num_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart (or not) filtering\n",
    "1. Select fragments which are present in train and not present in test and remove them\n",
    "2. For all the remaining ones: select top N (N=2000 or 0.95 model's compulative gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_present_in_test = np.unique(test_frag_matrix.indices)\n",
    "# %%timeit\n",
    "test_bits_counts = np.asarray(test_frag_matrix.sum(0)).reshape(-1)\n",
    "useful_bits = np.where(test_bits_counts > 0)[0]\n",
    "non_useful_bits = np.where(test_bits_counts == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ids_present_in_test & np.arange(test_frag_matrix.shape[1])\n",
    "#test_frag_matrix = test_frag_matrix[:, useful_bits]\n",
    "#train_frag_matrix = train_frag_matrix[:, useful_bits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_useful_bits = [int(x) for x in non_useful_bits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76281"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(useful_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True)\n",
    "tfidf_transformer.fit(train_frag_matrix)\n",
    "train_frag_matrix_transformed = tfidf_transformer.transform(train_frag_matrix)\n",
    "test_frag_matrix_transformed = tfidf_transformer.transform(test_frag_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219855,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.argsort(tfidf_transformer.idf_)\n",
    "tfidf_transformer.idf_[ids].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5758/5758 [11:30<00:00,  8.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from rdkit.ML.InfoTheory import InfoBitRanker\n",
    "ranker = InfoBitRanker(len(fps_train[0]), 2)\n",
    "activities = train_df.Active.values*1\n",
    "records_no_bits = []\n",
    "for i, (fp, activity) in enumerate(tqdm(zip(fps_train, activities), total=len(fps_train))):\n",
    "    fp.UnSetBitsFromList(non_useful_bits)\n",
    "    if fp.GetNumOnBits() == 0:\n",
    "        records_no_bits.append(i)\n",
    "        continue\n",
    "    ranker.AccumulateVotes(fp, int(activity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9702 0.013 52 31 cc<-O>c<-O>\n",
      "9700 0.012 57 31 c<-O>c<-O>\n",
      "9707 0.012 52 30 ccc<-O>c<-O>\n",
      "12252 0.012 51 29 cccc<-O>c<-O>\n",
      "50003 0.009 2 12 c<-O>c<-O>c<-O>\n",
      "50016 0.009 2 12 cc<-O>c<-O>c<-O>c\n",
      "50007 0.009 2 12 cc<-O>c<-O>c<-O>\n",
      "9718 0.008 30 19 c<-O>c<-O>ccC\n",
      "50078 0.008 2 11 c<-O>1cccc<-O>c<-O>1\n",
      "50014 0.008 2 11 ccc<-O>c<-O>c<-O>\n",
      "50035 0.008 2 11 ccc<-O>c<-O>c<-O>c\n",
      "50032 0.008 2 11 cccc<-O>c<-O>c<-O>\n",
      "21974 0.008 29 18 c<-O>c<-O>cc(c)C\n",
      "50037 0.007 3 11 c<-O>c<-O>cccc<-O>\n",
      "12263 0.007 46 19 c<-O>c<-O>cccc\n",
      "9709 0.006 47 19 cc<-O>c<-O>c\n",
      "9719 0.006 47 19 ccc<-O>c<-O>c\n",
      "21975 0.006 29 16 c<-O>c<-O>cccC\n",
      "21984 0.006 7 11 c<-O>c<-O>cc(c)CC\n",
      "21973 0.006 7 11 c<-O>c<-O>ccCC\n"
     ]
    }
   ],
   "source": [
    "top_values = ranker.GetTopN(4000)\n",
    "for identifier, gain, n0, n1 in top_values[:20]:\n",
    "    print(int(identifier),'%.3f'%gain,int(n0),int(n1), fcat.GetEntryDescription(int(identifier)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_indices = np.asarray([int(x[0]) for x in top_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bit_indices = useful_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.965371946946728"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED + 4)\n",
    "ids1 = np.where(train_df.Active == 1)[0]\n",
    "ids0 = np.where(train_df.Active == 0)[0]\n",
    "m = len(ids0)\n",
    "rebalanced = np.concatenate([\n",
    "    np.random.choice(ids1, m),\n",
    "    ids0]\n",
    ")\n",
    "subset_ids = np.concatenate([\n",
    "    np.random.choice(ids0, len(ids1)),\n",
    "    ids1\n",
    "])\n",
    "np.median(tfidf_transformer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(y_train):\n",
    "    df, counts = np.unique(y_train, return_counts=True)\n",
    "    m = counts.max()\n",
    "    index = np.arange(len(y_train))\n",
    "    new_index = []\n",
    "    for i, c in zip(df, counts):\n",
    "        ids = y_train == i\n",
    "        values = index[ids]\n",
    "        if c == m:\n",
    "            new_index.extend(values)\n",
    "        else:\n",
    "            new_index.extend(np.random.choice(values, m))\n",
    "    np.random.shuffle(new_index)\n",
    "    return new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5758x4000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 190586 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frag_matrix_transformed[:, bit_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf_transformer = TfidfTransformer(smooth_idf=True)\n",
    "#tfidf_transformer.fit(train_frag_matrix_transformed)\n",
    "#frag_matrix_transformed = tfidf_transformer.transform(train_frag_matrix_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Active.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527\n",
      "555\n",
      "534\n",
      "531\n",
      "550\n",
      "536\n",
      "528\n",
      "537\n",
      "520\n",
      "540\n",
      "537\n",
      "514\n",
      "532\n",
      "536\n",
      "534\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED + 5)\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "NFOLDS = 15#11\n",
    "BALANCE_TRAIN = True\n",
    "y_full_train = train_df.Active.values.astype(int)\n",
    "kf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED + 8)\n",
    "kfsplits = kf.split(np.arange(train_df.shape[0]), y_full_train)\n",
    "split_data = dict()\n",
    "all_train_scores = []\n",
    "all_train_scores_rebalanced = []\n",
    "all_test_scores = []\n",
    "for fold, (train_index, test_index) in enumerate(kfsplits):\n",
    "    split_data[fold] = (train_index, test_index)\n",
    "    x_train = train_frag_matrix_transformed[train_index][:, bit_indices]\n",
    "    y_train = y_full_train[train_index]\n",
    "    x_val = train_frag_matrix_transformed[test_index][:, bit_indices]\n",
    "    y_val = y_full_train[test_index]\n",
    "    if BALANCE_TRAIN:\n",
    "        balanced_index = balance_data(y_train)\n",
    "        x_train = x_train[balanced_index]\n",
    "        y_train = y_train[balanced_index]\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x_train, y_train)\n",
    "    train_preds = model.predict(train_frag_matrix_transformed[:, bit_indices])\n",
    "    train_scores = model.predict_proba(train_frag_matrix_transformed[:, bit_indices])[:, 1]#[rebalanced])[:, 1] \n",
    "    print(train_preds.sum())\n",
    "    all_train_scores.append(train_scores)\n",
    "    train_scores_balanced = model.predict_proba(\n",
    "        train_frag_matrix_transformed[rebalanced][:, bit_indices]\n",
    "    )[:, 1]#[rebalanced])[:, 1]\n",
    "    all_train_scores_rebalanced.append(train_scores_balanced)\n",
    "\n",
    "    test_scores = model.predict_proba(\n",
    "        test_frag_matrix_transformed[:, bit_indices]\n",
    "    )[:, 1]#[rebalanced])[:, 1] \n",
    "    all_test_scores.append(test_scores)\n",
    "\n",
    "all_train_scores = np.stack(all_train_scores)\n",
    "all_train_scores_rebalanced = np.stack(all_train_scores_rebalanced)\n",
    "all_test_scores = np.stack(all_test_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5758x4000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 190586 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frag_matrix_transformed[:, bit_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Active\"] = train_df.Active.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(991,)\n",
      "Select threshold on train data without rebalancing 0.4487115140179196\n",
      "344 [0.5801444  0.583213   0.57761733] 0.4487115140179196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.79      0.78      0.79      5540\n",
      "      Active       0.79      0.80      0.79      5540\n",
      "\n",
      "    accuracy                           0.79     11080\n",
      "   macro avg       0.79      0.79      0.79     11080\n",
      "weighted avg       0.79      0.79      0.79     11080\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.99      0.78      0.87      5540\n",
      "      Active       0.13      0.80      0.22       218\n",
      "\n",
      "    accuracy                           0.78      5758\n",
      "   macro avg       0.56      0.79      0.55      5758\n",
      "weighted avg       0.96      0.78      0.85      5758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, f1_score\n",
    "\n",
    "neg = (~train_df.Active).sum()\n",
    "pos = (train_df.Active).sum()\n",
    "train_scores = all_train_scores.mean(0)\n",
    "train_scores_rebalanced = all_train_scores_rebalanced.mean(0)\n",
    "fpr1, tpr1, thresholds1 = roc_curve(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced\n",
    ")\n",
    "print(tpr1.shape)\n",
    "opt_tpr_fpr1 = np.argmax(tpr1-fpr1)\n",
    "optimal_threshold1 = thresholds1[opt_tpr_fpr1]\n",
    "print(\"Select threshold on train data without rebalancing\", optimal_threshold1)\n",
    "print(opt_tpr_fpr1, tpr1[opt_tpr_fpr1-1:opt_tpr_fpr1+2]-fpr1[opt_tpr_fpr1-1:opt_tpr_fpr1+2], optimal_threshold1)\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold1,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold1,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03786036818339701"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Active.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(958,)\n",
      "Select threshold on train data without rebalancing 0.5194611816343447\n",
      "187 [0.55045044 0.54774285 0.55691717] 0.5194611816343447\n",
      "on balanced train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.71      0.94      0.81      5540\n",
      "      Active       0.91      0.61      0.73      5540\n",
      "\n",
      "    accuracy                           0.78     11080\n",
      "   macro avg       0.81      0.78      0.77     11080\n",
      "weighted avg       0.81      0.78      0.77     11080\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.98      0.94      0.96      5540\n",
      "      Active       0.29      0.61      0.39       218\n",
      "\n",
      "    accuracy                           0.93      5758\n",
      "   macro avg       0.64      0.77      0.68      5758\n",
      "weighted avg       0.96      0.93      0.94      5758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fpr, tpr, thresholds = roc_curve(\n",
    "    train_df.Active.values,\n",
    "    train_scores\n",
    ")\n",
    "print(tpr.shape)\n",
    "tp = tpr*pos\n",
    "fp = fpr*neg\n",
    "fn = (1-tpr)*pos\n",
    "f1 = 2*tp/(2*tp+fp+fn)\n",
    "opt_tpr_fpr = np.argmax(f1)\n",
    "optimal_threshold2 = thresholds[opt_tpr_fpr]\n",
    "print(\"Select threshold on train data without rebalancing\", optimal_threshold2)\n",
    "print(opt_tpr_fpr, tpr[opt_tpr_fpr-1:opt_tpr_fpr+2]-fpr[opt_tpr_fpr-1:opt_tpr_fpr+2], optimal_threshold2)\n",
    "print(\"on balanced train\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select threshold based on mean Active value 0.962139631816603\n",
      "on balanced train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.71      0.94      0.81      5540\n",
      "      Active       0.91      0.61      0.73      5540\n",
      "\n",
      "    accuracy                           0.78     11080\n",
      "   macro avg       0.81      0.78      0.77     11080\n",
      "weighted avg       0.81      0.78      0.77     11080\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.98      0.94      0.96      5540\n",
      "      Active       0.29      0.61      0.39       218\n",
      "\n",
      "    accuracy                           0.93      5758\n",
      "   macro avg       0.64      0.77      0.68      5758\n",
      "weighted avg       0.96      0.93      0.94      5758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimal_threshold3 = 1. - train_df.Active.mean()\n",
    "print(\"Select threshold based on mean Active value\", optimal_threshold3)\n",
    "print(\"on balanced train\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.exp(1)**model.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.ML.InfoTheory import InfoBitRanker\n",
    "# ranker = InfoBitRanker(len(fps[0]), 2)\n",
    "# activities = train_df.Active.values*1\n",
    "# for fp, activity in zip(fps, activities):\n",
    "#     ranker.AccumulateVotes(fp, int(activity))\n",
    "# top5 = ranker.GetTopN(15)\n",
    "# for id,gain,n0,n1 in top5:\n",
    "#     print(int(id),'%.3f'%gain,int(n0),int(n1), fcat.GetEntryDescription(int(id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdkit.ML.InfoTheory.BitClusterer.BitClusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = all_test_scores.mean(0) > optimal_threshold2 # > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Active\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.cleaner import collect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>NS(=O)(=O)c1cc2c(cc1Cl)NC(C1CC3C=CC1C3)NS2(=O)=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>Cc1cccc(Nc2ccncc2S(=O)(=O)NC(=O)NC(C)C)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>CCCC(=O)O[C@]1(C(=O)CO)CC[C@H]2[C@@H]3CCC4=CC(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>CN(C)c1cccc(Oc2cnc(Nc3cccc(O)c3)nc2)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>O=C(O)c1ccccc1-c1c2ccc(=O)cc-2oc2cc(O)ccc12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles\n",
       "1609   NS(=O)(=O)c1cc2c(cc1Cl)NC(C1CC3C=CC1C3)NS2(=O)=O\n",
       "1610          Cc1cccc(Nc2ccncc2S(=O)(=O)NC(=O)NC(C)C)c1\n",
       "1611  CCCC(=O)O[C@]1(C(=O)CO)CC[C@H]2[C@@H]3CCC4=CC(...\n",
       "1612             CN(C)c1cccc(Oc2cnc(Nc3cccc(O)c3)nc2)c1\n",
       "1613        O=C(O)c1ccccc1-c1c2ccc(=O)cc-2oc2cc(O)ccc12"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv(DATAPATH/\"test.csv\", index_col=0)\n",
    "submission_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_df.groupby(\"original_Smiles\").agg({\n",
    "    # \"Smiles\": lambda x: \".\".join(x),\n",
    "    \"Active\": lambda x: x.any(),\n",
    "    # \"original_Smiles\": \"first\"\n",
    "}).reset_index()\n",
    "activity_dict = {smiles: activity for smiles, activity in df.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"Active\"] = submission_df.Smiles.apply(lambda x: activity_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"../tmp/multinomial_nb_all_frags_balanced_cleaned_v4_4000_nfolds15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d632e93423067b2b9b1b8d52846f85c868da433699adad534ad2cc6673775271"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
