{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Custom fingerprints based on rdkit data. \n",
    "Various other things.\n",
    "\n",
    "I need this notebook simply for the code drafts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import RDConfig\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "IPythonConsole.drawOptions.addAtomIndices = False\n",
    "IPythonConsole.drawOptions.addStereoAnnotation = True\n",
    "IPythonConsole.drawOptions.useBWAtomPalette()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from rdkit.Chem import rdMolHash\n",
    "TMP_DIR = Path(\"../tmp\")\n",
    "PHARPATH = Path(\"../tmp/pharmacophores\")\n",
    "DATAPATH = Path(\"../data\")\n",
    "\n",
    "train_df = pd.read_csv(DATAPATH/\"train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(DATAPATH/\"test.csv\", index_col=0)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build library of the molecular fragments and use it\n",
    "https://www.rdkit.org/docs/GettingStartedInPython.html#molecular-fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fName=os.path.join(RDConfig.RDDataDir,'FunctionalGroups.txt')\n",
    "from rdkit.Chem import FragmentCatalog\n",
    "fparams = FragmentCatalog.FragCatParams(1,6,fName)\n",
    "fparams.GetNumFuncGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcat = FragmentCatalog.FragCatalog(fparams)\n",
    "fcgen = FragmentCatalog.FragCatGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5557/5557 [06:00<00:00, 15.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for smiles in tqdm(train_df.Smiles.values):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fcgen.AddFragsFromMol(mol, fcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221893"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcat.GetNumEntries()  # a lot - need to use sparse data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgen = FragmentCatalog.FragFPGenerator()\n",
    "#fp = fpgen.GetFPForMol(ms[8],fcat)\n",
    "#fp.GetNumOnBits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mols = [Chem.MolFromSmiles(smiles) for smiles in train_df.Smiles.values]\n",
    "test_mols = [Chem.MolFromSmiles(smiles) for smiles in test_df.Smiles.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5557/5557 [03:56<00:00, 23.47it/s]\n",
      "100%|██████████| 1614/1614 [00:59<00:00, 27.28it/s]\n"
     ]
    }
   ],
   "source": [
    "fps_train = []\n",
    "for x in tqdm(train_mols):\n",
    "    fps_train.append(fpgen.GetFPForMol(x, fcat))\n",
    "fps_test = []\n",
    "for x in tqdm(test_mols):\n",
    "    fps_test.append(fpgen.GetFPForMol(x, fcat))\n",
    "\n",
    "# fps_test = [fpgen.GetFPForMol(x, fcat) for x in train_mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7fd9ce7313f0>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7fd9ce731440>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7fd9ce731490>,\n",
       " <rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x7fd9ce7314e0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = fpgen.GetFPForMol(train_mols[0],fcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5557/5557 [00:13<00:00, 414.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# np.asarray(fp).shape\n",
    "from scipy.sparse import csr_matrix\n",
    "num_fp = fcat.GetNumEntries()\n",
    "num_entries = len(fps_train)\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "for i, fp in enumerate(tqdm(fps_train)):\n",
    "    bits = list(fp.GetOnBits())\n",
    "    col_indices.extend(bits)\n",
    "    row_indices.extend([i]*len(bits))\n",
    "col_indices = np.asarray(col_indices)\n",
    "row_indices = np.asarray(row_indices)\n",
    "assert len(col_indices) == len(row_indices)\n",
    "values = np.ones((len(col_indices), ))\n",
    "train_frag_matrix = csr_matrix((values, (row_indices, col_indices)), shape=(num_entries, num_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [00:05<00:00, 294.88it/s]\n"
     ]
    }
   ],
   "source": [
    "row_indices = []\n",
    "col_indices = []\n",
    "for i, fp in enumerate(tqdm(fps_test)):\n",
    "    bits = list(fp.GetOnBits())\n",
    "    col_indices.extend(bits)\n",
    "    row_indices.extend([i]*len(bits))\n",
    "col_indices = np.asarray(col_indices)\n",
    "row_indices = np.asarray(row_indices)\n",
    "assert len(col_indices) == len(row_indices)\n",
    "values = np.ones((len(col_indices), ))\n",
    "test_frag_matrix = csr_matrix((values, (row_indices, col_indices)), shape=(len(fps_test), num_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart (or not) filtering\n",
    "1. Select fragments which are present in train and not present in test and remove them\n",
    "2. For all the remaining ones: select top N (N=2000 or 0.95 model's compulative gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_present_in_test = np.unique(test_frag_matrix.indices)\n",
    "# %%timeit\n",
    "test_bits_counts = np.asarray(test_frag_matrix.sum(0)).reshape(-1)\n",
    "useful_bits = np.where(test_bits_counts > 0)[0]\n",
    "non_useful_bits = np.where(test_bits_counts == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ids_present_in_test & np.arange(test_frag_matrix.shape[1])\n",
    "#test_frag_matrix = test_frag_matrix[:, useful_bits]\n",
    "#train_frag_matrix = train_frag_matrix[:, useful_bits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_useful_bits = [int(x) for x in non_useful_bits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True)\n",
    "tfidf_transformer.fit(train_frag_matrix)\n",
    "train_frag_matrix_transformed = tfidf_transformer.transform(train_frag_matrix)\n",
    "test_frag_matrix_transformed = tfidf_transformer.transform(test_frag_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221893,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.argsort(tfidf_transformer.idf_)\n",
    "tfidf_transformer.idf_[ids].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5557/5557 [12:48<00:00,  7.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from rdkit.ML.InfoTheory import InfoBitRanker\n",
    "ranker = InfoBitRanker(len(fps_train[0]), 2)\n",
    "activities = train_df.Active.values*1\n",
    "records_no_bits = []\n",
    "for i, (fp, activity) in enumerate(tqdm(zip(fps_train, activities), total=len(fps_train))):\n",
    "    fp.UnSetBitsFromList(non_useful_bits)\n",
    "    if fp.GetNumOnBits() == 0:\n",
    "        records_no_bits.append(i)\n",
    "        continue\n",
    "    ranker.AccumulateVotes(fp, int(activity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9702 0.013 52 31 c<-O>c<-O>ccCC\n",
      "9700 0.013 57 31 c<-O>c<-O>ccCC\n",
      "9707 0.013 52 30 c<-O>c<-O>ccCC\n",
      "12252 0.012 51 29 c<-O>c<-O>ccCC\n",
      "50160 0.009 2 12 c<-O>c<-O>ccCC\n",
      "50169 0.009 2 12 c<-O>c<-O>ccCC\n",
      "50156 0.009 2 12 c<-O>c<-O>ccCC\n",
      "9718 0.008 30 19 c<-O>c<-O>ccCC\n",
      "50185 0.008 2 11 c<-O>c<-O>ccCC\n",
      "50188 0.008 2 11 c<-O>c<-O>ccCC\n",
      "50231 0.008 2 11 c<-O>c<-O>ccCC\n",
      "50167 0.008 2 11 c<-O>c<-O>ccCC\n",
      "22012 0.008 29 18 c<-O>c<-O>ccCC\n",
      "50190 0.008 3 11 c<-O>c<-O>ccCC\n",
      "12263 0.007 46 19 c<-O>c<-O>ccCC\n",
      "9709 0.007 47 19 c<-O>c<-O>ccCC\n",
      "9719 0.007 47 19 c<-O>c<-O>ccCC\n",
      "22013 0.007 29 16 c<-O>c<-O>ccCC\n",
      "22011 0.006 7 11 c<-O>c<-O>ccCC\n",
      "22022 0.006 7 11 c<-O>c<-O>ccCC\n"
     ]
    }
   ],
   "source": [
    "top_values = ranker.GetTopN(2000)\n",
    "for identifier, gain, n0, n1 in top_values[:20]:\n",
    "    print(int(identifier),'%.3f'%gain,int(n0),int(n1), fcat.GetEntryDescription(int(id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_indices = np.asarray([int(x[0]) for x in top_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bit_indices = useful_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.62299361030245"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED + 4)\n",
    "ids1 = np.where(train_df.Active == 1)[0]\n",
    "ids0 = np.where(train_df.Active == 0)[0]\n",
    "m = len(ids0)\n",
    "rebalanced = np.concatenate([\n",
    "    np.random.choice(ids1, m),\n",
    "    ids0]\n",
    ")\n",
    "subset_ids = np.concatenate([\n",
    "    np.random.choice(ids0, len(ids1)),\n",
    "    ids1\n",
    "])\n",
    "np.median(tfidf_transformer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(y_train):\n",
    "    df, counts = np.unique(y_train, return_counts=True)\n",
    "    m = counts.max()\n",
    "    index = np.arange(len(y_train))\n",
    "    new_index = []\n",
    "    for i, c in zip(df, counts):\n",
    "        ids = y_train == i\n",
    "        values = index[ids]\n",
    "        if c == m:\n",
    "            new_index.extend(values)\n",
    "        else:\n",
    "            new_index.extend(np.random.choice(values, m))\n",
    "    np.random.shuffle(new_index)\n",
    "    return new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5557x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 121019 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frag_matrix_transformed[:, bit_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf_transformer = TfidfTransformer(smooth_idf=True)\n",
    "#tfidf_transformer.fit(train_frag_matrix_transformed)\n",
    "#frag_matrix_transformed = tfidf_transformer.transform(train_frag_matrix_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n",
      "474\n",
      "484\n",
      "509\n",
      "487\n",
      "520\n",
      "492\n",
      "494\n",
      "529\n",
      "528\n",
      "513\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED + 5)\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "NFOLDS = 11\n",
    "BALANCE_TRAIN = True\n",
    "y_full_train = train_df.Active.values\n",
    "kf = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED + 8)\n",
    "kfsplits = kf.split(np.arange(train_df.shape[0]), y_full_train)\n",
    "split_data = dict()\n",
    "all_train_scores = []\n",
    "all_train_scores_rebalanced = []\n",
    "all_test_scores = []\n",
    "for fold, (train_index, test_index) in enumerate(kfsplits):\n",
    "    split_data[fold] = (train_index, test_index)\n",
    "    x_train = train_frag_matrix_transformed[train_index][:, bit_indices]\n",
    "    y_train = y_full_train[train_index]\n",
    "    x_val = train_frag_matrix_transformed[test_index][:, bit_indices]\n",
    "    y_val = y_full_train[test_index]\n",
    "    if BALANCE_TRAIN:\n",
    "        balanced_index = balance_data(y_train)\n",
    "        x_train = x_train[balanced_index]\n",
    "        y_train = y_train[balanced_index]\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x_train, y_train)\n",
    "    train_preds = model.predict(train_frag_matrix_transformed[:, bit_indices])\n",
    "    train_scores = model.predict_proba(train_frag_matrix_transformed[:, bit_indices])[:, 1]#[rebalanced])[:, 1] \n",
    "    print(train_preds.sum())\n",
    "    all_train_scores.append(train_scores)\n",
    "    train_scores_balanced = model.predict_proba(\n",
    "        train_frag_matrix_transformed[rebalanced][:, bit_indices]\n",
    "    )[:, 1]#[rebalanced])[:, 1]\n",
    "    all_train_scores_rebalanced.append(train_scores_balanced)\n",
    "\n",
    "    test_scores = model.predict_proba(\n",
    "        test_frag_matrix_transformed[:, bit_indices]\n",
    "    )[:, 1]#[rebalanced])[:, 1] \n",
    "    all_test_scores.append(test_scores)\n",
    "\n",
    "all_train_scores = np.stack(all_train_scores)\n",
    "all_train_scores_rebalanced = np.stack(all_train_scores_rebalanced)\n",
    "all_test_scores = np.stack(all_test_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5557x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 121019 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frag_matrix_transformed[:, bit_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912,)\n",
      "Select threshold on train data without rebalancing 0.5009792646235678\n",
      "201 [0.51261446 0.51579144 0.51429639] 0.5009792646235678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.69      0.93      0.79      5351\n",
      "      Active       0.89      0.58      0.71      5351\n",
      "\n",
      "    accuracy                           0.76     10702\n",
      "   macro avg       0.79      0.76      0.75     10702\n",
      "weighted avg       0.79      0.76      0.75     10702\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.98      0.93      0.96      5351\n",
      "      Active       0.24      0.58      0.34       206\n",
      "\n",
      "    accuracy                           0.92      5557\n",
      "   macro avg       0.61      0.75      0.65      5557\n",
      "weighted avg       0.96      0.92      0.93      5557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, f1_score\n",
    "\n",
    "neg = (~train_df.Active).sum()\n",
    "pos = (train_df.Active).sum()\n",
    "train_scores = all_train_scores.mean(0)\n",
    "train_scores_rebalanced = all_train_scores_rebalanced.mean(0)\n",
    "fpr1, tpr1, thresholds1 = roc_curve(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced\n",
    ")\n",
    "print(tpr1.shape)\n",
    "opt_tpr_fpr1 = np.argmax(tpr1-fpr1)\n",
    "optimal_threshold1 = thresholds1[opt_tpr_fpr1]\n",
    "print(\"Select threshold on train data without rebalancing\", optimal_threshold1)\n",
    "print(opt_tpr_fpr1, tpr1[opt_tpr_fpr1-1:opt_tpr_fpr1+2]-fpr1[opt_tpr_fpr1-1:opt_tpr_fpr1+2], optimal_threshold1)\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold1,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold1,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03707036170595645"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Active.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(870,)\n",
      "Select threshold on train data without rebalancing 0.7714842680655122\n",
      "86 [0.36555457 0.37526331 0.37414203] 0.7714842680655122\n",
      "on balanced train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.62      0.98      0.76      5351\n",
      "      Active       0.96      0.39      0.56      5351\n",
      "\n",
      "    accuracy                           0.69     10702\n",
      "   macro avg       0.79      0.69      0.66     10702\n",
      "weighted avg       0.79      0.69      0.66     10702\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.98      0.98      0.98      5351\n",
      "      Active       0.45      0.39      0.42       206\n",
      "\n",
      "    accuracy                           0.96      5557\n",
      "   macro avg       0.72      0.69      0.70      5557\n",
      "weighted avg       0.96      0.96      0.96      5557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fpr, tpr, thresholds = roc_curve(\n",
    "    train_df.Active.values,\n",
    "    train_scores\n",
    ")\n",
    "print(tpr.shape)\n",
    "tp = tpr*pos\n",
    "fp = fpr*neg\n",
    "fn = (1-tpr)*pos\n",
    "f1 = 2*tp/(2*tp+fp+fn)\n",
    "opt_tpr_fpr = np.argmax(f1)\n",
    "optimal_threshold2 = thresholds[opt_tpr_fpr]\n",
    "print(\"Select threshold on train data without rebalancing\", optimal_threshold2)\n",
    "print(opt_tpr_fpr, tpr[opt_tpr_fpr-1:opt_tpr_fpr+2]-fpr[opt_tpr_fpr-1:opt_tpr_fpr+2], optimal_threshold2)\n",
    "print(\"on balanced train\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select threshold based on mean Active value 0.9629296382940435\n",
      "on balanced train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.62      0.98      0.76      5351\n",
      "      Active       0.96      0.39      0.56      5351\n",
      "\n",
      "    accuracy                           0.69     10702\n",
      "   macro avg       0.79      0.69      0.66     10702\n",
      "weighted avg       0.79      0.69      0.66     10702\n",
      "\n",
      "the same threshold, on train data without rebalancing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Inactive       0.98      0.98      0.98      5351\n",
      "      Active       0.45      0.39      0.42       206\n",
      "\n",
      "    accuracy                           0.96      5557\n",
      "   macro avg       0.72      0.69      0.70      5557\n",
      "weighted avg       0.96      0.96      0.96      5557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimal_threshold3 = 1. - train_df.Active.mean()\n",
    "print(\"Select threshold based on mean Active value\", optimal_threshold3)\n",
    "print(\"on balanced train\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values[rebalanced],\n",
    "    train_scores_rebalanced > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")\n",
    "print(\"the same threshold, on train data without rebalancing\")\n",
    "print(classification_report(\n",
    "    train_df.Active.values,\n",
    "    train_scores > optimal_threshold2,\n",
    "    target_names=['Inactive', 'Active']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.exp(1)**model.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.ML.InfoTheory import InfoBitRanker\n",
    "# ranker = InfoBitRanker(len(fps[0]), 2)\n",
    "# activities = train_df.Active.values*1\n",
    "# for fp, activity in zip(fps, activities):\n",
    "#     ranker.AccumulateVotes(fp, int(activity))\n",
    "# top5 = ranker.GetTopN(15)\n",
    "# for id,gain,n0,n1 in top5:\n",
    "#     print(int(id),'%.3f'%gain,int(n0),int(n1), fcat.GetEntryDescription(int(id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdkit.ML.InfoTheory.BitClusterer.BitClusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = all_test_scores.mean(0) > optimal_threshold2 # > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Active\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../tmp/multinomial_nb_all_frags_balanced_filtered_v3_2000_nfolds11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d632e93423067b2b9b1b8d52846f85c868da433699adad534ad2cc6673775271"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
